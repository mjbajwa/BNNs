{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc3 as pm\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import arviz as az\n",
    "import lasagne\n",
    "import os\n",
    "import datetime\n",
    "import re\n",
    "\n",
    "floatX = theano.config.floatX\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants (parse to log files)\n",
    "\n",
    "ITER = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "\n",
    "    # Load Data\n",
    "\n",
    "    df = pd.read_table(\"../data/rdata\", header=None, delim_whitespace=True)\n",
    "    df.columns = [\"X\", \"Y\"]\n",
    "    df[\"index\"] = np.where(df.index < 100, \"Train\", \"Test\")\n",
    "\n",
    "    # Create train and test\n",
    "\n",
    "    X_train = np.array(df.loc[df[\"index\"] == \"Train\", \"X\"]).reshape(-1, 1)\n",
    "    Y_train = np.array(df.loc[df[\"index\"] == \"Train\", \"Y\"])\n",
    "    X_test = np.array(df.loc[df[\"index\"] == \"Test\", \"X\"]).reshape(-1, 1)\n",
    "    Y_test = np.array(df.loc[df[\"index\"] == \"Test\", \"Y\"])\n",
    "\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-centered parametrization\n",
    "\n",
    "n_hidden = [8]\n",
    "\n",
    "# Initialize random weights between each layer\n",
    "\n",
    "init_w_ih = np.zeros((X_train.shape[1], n_hidden[0])).astype(floatX)\n",
    "init_w_ho = np.zeros((n_hidden[0], 1)).astype(floatX)\n",
    "init_b_h = np.zeros((n_hidden[0], )).astype(floatX)\n",
    "init_b_o = np.zeros((1, )).astype(floatX)\n",
    "\n",
    "with pm.Model() as neural_network:\n",
    "\n",
    "    bnn_input = theano.shared(X_train)\n",
    "    bnn_output = theano.shared(Y_train)\n",
    "\n",
    "    # ==== Hyperparameter Prior Definition (Precision)\n",
    "\n",
    "    prec_w_ih = pm.Gamma(\"W_prec_ih\", alpha=0.25, beta=0.000625, testval = 1)\n",
    "    prec_w_ho = pm.Gamma(\"W_prec_ho\", alpha=0.25, beta=7.8125e-05, testval = 1)\n",
    "    prec_b_h = pm.Gamma(\"B_prec_h\", alpha=0.25, beta=0.000625, testval = 1)\n",
    "    prec_target = pm.Gamma(\"y_prec\", alpha=0.25, beta=0.000625, testval = 1)\n",
    "\n",
    "    # ==== Re-parametrized\n",
    "\n",
    "    weights_ih_raw = pm.Normal(\"w_ih\", mu=0, sigma=1, shape=(X_train.shape[1], n_hidden[0]), testval=init_w_ih)\n",
    "\n",
    "    # Weights from hidden layer to output\n",
    "\n",
    "    weights_ho_raw = pm.Normal(\"w_ho\", mu=0, sigma=1, shape=(n_hidden[0], 1), testval=init_w_ho)\n",
    "\n",
    "    # Hidden Biases\n",
    "    \n",
    "    biases_h_raw = pm.Normal(\"b_h\", mu=0, sigma=1, shape=(n_hidden[0], ), testval=init_b_h)\n",
    "\n",
    "    # Weights from input to hidden layer\n",
    "\n",
    "    weights_ih = 1/np.sqrt(prec_w_ih) * weights_ih_raw\n",
    "\n",
    "    # Weights from hidden layer to output\n",
    "\n",
    "    weights_ho = (1/np.sqrt(prec_w_ho))*weights_ho_raw\n",
    "\n",
    "    # Biases of hidden layer\n",
    "\n",
    "    biases_h = 1/np.sqrt(prec_b_h)*biases_h_raw\n",
    "\n",
    "    # Biases of output layer\n",
    "\n",
    "    biases_o = pm.Normal(\"b_o\", mu=0, sigma=100, shape=(1,), testval=init_b_o)\n",
    "\n",
    "    # ==== Forward Pass of the Neural Network \n",
    "\n",
    "    # Build neural-network using Lasagne (keras equivalent)\n",
    "\n",
    "    act_in = lasagne.layers.InputLayer(X_train.shape, input_var=bnn_input)\n",
    "\n",
    "    act_h = lasagne.layers.DenseLayer(incoming=act_in, \n",
    "                                      num_units=n_hidden[0], \n",
    "                                      W=weights_ih,\n",
    "                                      b=biases_h,    \n",
    "                                      nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "    act_out = lasagne.layers.DenseLayer(incoming=act_h, \n",
    "                                        num_units=1, \n",
    "                                        W=weights_ho, \n",
    "                                        b=biases_o)\n",
    "\n",
    "    net_out = lasagne.layers.get_output(act_out)\n",
    "\n",
    "    # Add likelihood function\n",
    "\n",
    "    output = pm.Normal(\"output\", net_out.flatten(), sigma=1/np.sqrt(prec_target), observed=bnn_output)\n",
    "\n",
    "    # Sampling methods\n",
    "\n",
    "    # step1 = pm.NUTS([prec_w_ih, prec_w_ho, prec_b_h, prec_target])\n",
    "    # step2 = pm.NUTS([weights_ih, weights_ho, biases_h, biases_o])\n",
    "    # steps = pm.CompoundStep([step1, step2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Auto-assigning NUTS sampler...\n",
      "Initializing NUTS using jitter+adapt_diag...\n",
      "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
      "WARNING (theano.tensor.blas): We did not find a dynamic library in the library_dir of the library we use for blas. If you use ATLAS, make sure to compile it with dynamics library.\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "NUTS: [b_o, b_h, w_ho, w_ih, y_prec, B_prec_h, W_prec_ho, W_prec_ih]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='84000' class='' max='84000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [84000/84000 53:50<00:00 Sampling 4 chains, 26,323 divergences]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling 4 chains for 1_000 tune and 20_000 draw iterations (4_000 + 80_000 draws total) took 3231 seconds.\n",
      "There were 10611 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The acceptance probability does not match the target. It is 0.6455767592033724, but should be close to 0.8. Try to increase the number of tuning steps.\n",
      "There were 2608 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "There were 6834 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.\n",
      "There were 6270 divergences after tuning. Increase `target_accept` or reparameterize.\n",
      "The rhat statistic is larger than 1.4 for some parameters. The sampler did not converge.\n",
      "The estimated number of effective samples is smaller than 200 for some parameters.\n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "\n",
    "with neural_network:\n",
    "    \n",
    "    trace = pm.sample(draws=ITER, \n",
    "                      chains=4,\n",
    "                      cores=4,\n",
    "                      discard_tuned_samples=True,\n",
    "                      return_inferencedata=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trace Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mjbajwa/anaconda3/lib/python3.6/site-packages/pymc3/sampling.py:1708: UserWarning:\n",
      "\n",
      "samples parameter is smaller than nchains times ndraws, some draws and/or chains may not be represented in the returned posterior predictive sample\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='20000' class='' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [20000/20000 02:29<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mjbajwa/anaconda3/lib/python3.6/site-packages/pymc3/sampling.py:1708: UserWarning:\n",
      "\n",
      "samples parameter is smaller than nchains times ndraws, some draws and/or chains may not be represented in the returned posterior predictive sample\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='20000' class='' max='20000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [20000/20000 02:29<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train predictions\n",
    "\n",
    "with neural_network:\n",
    "    ppc_train = pm.sample_posterior_predictive(\n",
    "        trace, var_names=[\"output\"], random_seed=42, samples=ITER,\n",
    "    )\n",
    "\n",
    "# Test predictions\n",
    "    \n",
    "bnn_input.set_value(X_test)\n",
    "bnn_output.set_value(Y_test)\n",
    "\n",
    "with neural_network:\n",
    "    ppc_test = pm.sample_posterior_predictive(\n",
    "        trace, var_names=[\"output\"], random_seed=42, samples=ITER,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions_train = pd.DataFrame({\n",
    "    \n",
    "    \"inputs\": X_train.flatten(),\n",
    "    \"targets\": Y_train.flatten(),\n",
    "    \"mean\": ppc_train[\"output\"].mean(axis=0),\n",
    "    \"median\": np.quantile(ppc_train[\"output\"], 0.5, axis=0),\n",
    "    \"q1\": np.quantile(ppc_train[\"output\"], 0.01, axis=0),\n",
    "    \"q10\": np.quantile(ppc_train[\"output\"], 0.10, axis=0),\n",
    "    \"q90\": np.quantile(ppc_train[\"output\"], 0.90, axis=0),\n",
    "    \"q99\": np.quantile(ppc_train[\"output\"], 0.99, axis=0),\n",
    "    \"label\": \"train\"\n",
    "\n",
    "})\n",
    "\n",
    "\n",
    "df_predictions_test = pd.DataFrame({\n",
    "    \n",
    "    \"inputs\": X_test.flatten(),\n",
    "    \"targets\": Y_test.flatten(),\n",
    "    \"mean\": ppc_test[\"output\"].mean(axis=0),\n",
    "    \"median\": np.quantile(ppc_test[\"output\"], 0.5, axis=0),\n",
    "    \"q1\": np.quantile(ppc_test[\"output\"], 0.01, axis=0),\n",
    "    \"q10\": np.quantile(ppc_test[\"output\"], 0.10, axis=0),\n",
    "    \"q90\": np.quantile(ppc_test[\"output\"], 0.90, axis=0),\n",
    "    \"q99\": np.quantile(ppc_test[\"output\"], 0.99, axis=0),\n",
    "    \"label\": \"test\"\n",
    "\n",
    "})\n",
    "\n",
    "df_predictions = pd.concat([df_predictions_train, df_predictions_test]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Traces\n",
    "\n",
    "df_traces = pm.trace_to_dataframe(trace,\n",
    "                                  chains=[0,1,2,3],\n",
    "                                  varnames=[\"W_prec_ih\", \"W_prec_ho\", \"B_prec_h\", \"y_prec\", \"w_ih\", \"w_ho\", \"b_h\", \"b_o\"])\n",
    "\n",
    "df_traces[\"id\"] = df_traces.index\n",
    "\n",
    "df_traces[\"trace\"] = np.where(np.logical_and(df_traces[\"id\"] >= 0, df_traces[\"id\"] < ITER), 1, \n",
    "                                  np.where(np.logical_and(df_traces[\"id\"] >= ITER, df_traces[\"id\"] < 2*ITER), 2, \n",
    "                                      np.where(np.logical_and(df_traces[\"id\"] >= 2*ITER, df_traces[\"id\"] < 3*ITER), 3, \n",
    "                                              np.where(np.logical_and(df_traces[\"id\"] >= 3*ITER, df_traces[\"id\"] <= 4*ITER), 4, 4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_by_precision(df_traces, primary, precision):\n",
    "    \n",
    "    df_traces[primary] = df_traces[primary].div(np.sqrt(df_traces[precision]), axis=0)\n",
    "    \n",
    "    return df_traces\n",
    "\n",
    "w_ih_cols = [col for col in df_traces.columns if re.match(\"w_ih_\", col)]\n",
    "b_h_cols = [col for col in df_traces.columns if re.match(\"b_h_\", col)]\n",
    "w_ho_cols = [col for col in df_traces.columns if re.match(\"w_ho_\", col)]\n",
    "b_o_cols = [col for col in df_traces.columns if re.match(\"b_o_\", col)]\n",
    "\n",
    "df_traces = divide_by_precision(df_traces, w_ih_cols, \"W_prec_ih\")\n",
    "df_traces = divide_by_precision(df_traces, b_h_cols, \"B_prec_h\")\n",
    "df_traces = divide_by_precision(df_traces, w_ho_cols, \"W_prec_ho\")\n",
    "df_traces[b_o_cols] = df_traces[b_o_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to disk\n",
    "\n",
    "time = datetime.datetime.now().strftime('%Y_%m_%d_%H_%M_%S')\n",
    "new_dir = os.path.join(\"../output/\", \"pymc3_nc_\" + time)\n",
    "os.mkdir(new_dir)\n",
    "df_traces.to_feather(f\"{new_dir}/df_traces.feather\")\n",
    "df_predictions.drop(f\"index\", axis=1).to_feather(f\"{new_dir}/df_predictions.feather\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../output/pymc3_nc_2021_03_23_13_41_24\n"
     ]
    }
   ],
   "source": [
    "print(new_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
